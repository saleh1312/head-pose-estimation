{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Untitled9.ipynb","provenance":[{"file_id":"1RUSP8cpg7xbtEa22FaAdYHb9fJn1Mc2E","timestamp":1603096114961}],"collapsed_sections":[],"authorship_tag":"ABX9TyM90oLTnxq58/h5KLwUH1nl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GVXEooyy4Sb8"},"source":["**this code used in colab**\n","\n","\n","**you can change the path of link to file \"shape_predictor_68_face_landmarks.dat.dat\" see** [link](https://www.youtube.com/watch?v=MrRGVOhARYY) **to understand how to do landmarks on images that i used in this code**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Xat3W9FzX3RQ"},"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import img_as_float,img_as_ubyte\n","import dlib\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT0M_MRcYDHR","executionInfo":{"status":"ok","timestamp":1603095889138,"user_tz":-120,"elapsed":34662,"user":{"displayName":"Prof Soft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiaDqV9emD_XHcCKCtBVYe0PPmysd-B7JfNYPmZ=s64","userId":"08982446338325414900"}},"outputId":"3fc9e8bb-fd2b-49a8-e80a-0db7c704ec19","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VjmLgr-WYFWm"},"source":["detector = dlib.get_frontal_face_detector()\n","predector = dlib.shape_predictor(\"/content/drive/My Drive/yolov3/shape_predictor_68_face_landmarks.dat\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYOib4aPQhDR"},"source":["def add_photo(img,pt2,mask):\n","  \n","  mask=img_as_float(mask)\n","  img=img_as_float(img)\n","  pt1=np.float32([[0,0],\n","                  [mask.shape[1],0],\n","                  [0,mask.shape[0]],\n","                  [mask.shape[1],mask.shape[0]]\n","\n","                  ])\n","  mat = cv2.getPerspectiveTransform(pt1,pt2)\n","  res=cv2.warpPerspective(mask,mat,(img.shape[1],img.shape[0]),cv2.INTER_LINEAR,cv2.BORDER_CONSTANT,borderValue=(-1, -1, -1))\n","  \n","  return res\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j11R_WycYI_F"},"source":["def pro(img,mask,draw_rect1=True,draw_rect2=True,draw_lines=True,draw_mask=True):\n","  \n","    \n","  copy = img.copy()\n","\n","  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","\n"," \n","\n","  faces=detector(gray)\n","\n","  for face in faces:\n","    x1 = face.left()\n","    y1 =face.top()\n","    x2= face.right()\n","    y2= face.bottom()\n","    landmarks = predector(gray,face)\n","\n","    \n","    size = copy.shape\n","        \n","    #2D image points. If you change the image, you need to change vector\n","    image_points = np.array([\n","                                (landmarks.part(33).x,landmarks.part(33).y),     # Nose tip\n","                                (landmarks.part(8).x,landmarks.part(8).y),       # Chin\n","                                (landmarks.part(36).x,landmarks.part(36).y),     # Left eye left corner\n","                                (landmarks.part(45).x,landmarks.part(45).y),     # Right eye right corne\n","                                (landmarks.part(48).x,landmarks.part(48).y),     # Left Mouth corner\n","                                (landmarks.part(54).x,landmarks.part(54).y)      # Right mouth corner\n","                            ], dtype=\"double\")\n","\n","    # 3D model points.\n","    model_points = np.array([\n","                                (0.0, 0.0, 0.0),             # Nose tip\n","                                (0.0, -330.0, -65.0),        # Chin\n","                                (-225.0, 170.0, -135.0),     # Left eye left corner\n","                                (225.0, 170.0, -135.0),      # Right eye right corne\n","                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n","                                (150.0, -150.0, -125.0)      # Right mouth corner\n","                            \n","                            ])\n","\n","\n","    # Camera internals\n","\n","    focal_length = size[1]\n","    center = (size[1]/2, size[0]/2)\n","    camera_matrix = np.array(\n","                            [[focal_length, 0, center[0]],\n","                            [0, focal_length, center[1]],\n","                            [0, 0, 1]], dtype = \"double\"\n","                            )\n","\n","    \n","\n","    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n","    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n","\n","    \n","    (b1, jacobian) = cv2.projectPoints(np.array([(350.0, 270.0, 0.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b2, jacobian) = cv2.projectPoints(np.array([(-350.0, -270.0, 0.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b3, jacobian) = cv2.projectPoints(np.array([(-350.0, 270, 0.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b4, jacobian) = cv2.projectPoints(np.array([(350.0, -270.0, 0.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    \n","    \n","    (b11, jacobian) = cv2.projectPoints(np.array([(450.0, 350.0, 400.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b12, jacobian) = cv2.projectPoints(np.array([(-450.0, -350.0, 400.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b13, jacobian) = cv2.projectPoints(np.array([(-450.0, 350, 400.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","    (b14, jacobian) = cv2.projectPoints(np.array([(450.0, -350.0, 400.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n","\n","\n","    b1 = ( int(b1[0][0][0]), int(b1[0][0][1]))\n","    b2 = ( int(b2[0][0][0]), int(b2[0][0][1]))\n","    b3 = ( int(b3[0][0][0]), int(b3[0][0][1]))\n","    b4 = ( int(b4[0][0][0]), int(b4[0][0][1]))\n","\n","    b11 = ( int(b11[0][0][0]), int(b11[0][0][1]))\n","    b12 = ( int(b12[0][0][0]), int(b12[0][0][1]))\n","    b13 = ( int(b13[0][0][0]), int(b13[0][0][1]))\n","    b14 = ( int(b14[0][0][0]), int(b14[0][0][1]))\n","\n","    if draw_rect1 ==True:\n","\n","      cv2.line(copy,b1,b3,(255,255,0),10)\n","      cv2.line(copy,b3,b2,(255,255,0),10)\n","      cv2.line(copy,b2,b4,(255,255,0),10)\n","      cv2.line(copy,b4,b1,(255,255,0),10)\n","\n","    if draw_rect2 ==True:\n","\n","      cv2.line(copy,b11,b13,(255,255,0),10)\n","      cv2.line(copy,b13,b12,(255,255,0),10)\n","      cv2.line(copy,b12,b14,(255,255,0),10)\n","      cv2.line(copy,b14,b11,(255,255,0),10)\n","    \n","    if draw_lines == True:\n","\n","\n","      cv2.line(copy,b11,b1,(0,255,0),10)\n","      cv2.line(copy,b13,b3,(0,255,0),10)\n","      cv2.line(copy,b12,b2,(0,255,0),10)\n","      cv2.line(copy,b14,b4,(0,255,0),10)\n","\n","    if draw_mask ==True:\n","      pt=np.float32([b11,b13,b14,b12])\n","\n","      ty=add_photo(copy,pt,mask)\n","      tb= img_as_ubyte(ty)\n","      for i in range(0,ty.shape[0]):\n","        for j in range(0,ty.shape[1]):\n","          k=ty[i,j]\n","          if k[0] != -1 and k[1] != -1 and k[2] != -1:\n","            copy[i,j] = tb[i,j]\n","  return copy\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwvAFIaRQ_BO","executionInfo":{"status":"ok","timestamp":1603095928846,"user_tz":-120,"elapsed":2193,"user":{"displayName":"Prof Soft","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiaDqV9emD_XHcCKCtBVYe0PPmysd-B7JfNYPmZ=s64","userId":"08982446338325414900"}},"outputId":"c7a169b2-3a76-4797-e7bf-e934ff1fdc3c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#change the photo \n","mask=cv2.imread(\"cat.jpg\")\n","\n","# the video\n","cap = cv2.VideoCapture(\"29.wmv\")\n","\n","if (cap.isOpened() == False): \n","  print(\"Unable to read camera feed\")\n","\n","\n","frame_width = int(cap.get(3))\n","frame_height = int(cap.get(4))\n","\n","\n","out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n","\n","while(True):\n","  ret, frame = cap.read()\n","\n","  if ret == True: \n","    \n","    res=pro(frame,mask,draw_mask=False)\n","    # Write the frame into the file 'output.avi'\n","    out.write(res)\n","\n","    \n","\n","  # Break the loop\n","  else:\n","    break  \n","\n","# When everything done, release the video capture and video write objects\n","cap.release()\n","out.release()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unable to read camera feed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V_OG0cCDW6Mp"},"source":[""],"execution_count":null,"outputs":[]}]}